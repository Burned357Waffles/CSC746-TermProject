#!/bin/bash -l
#SBATCH --constraint=cpu
#SBATCH --cpus-per-task=1
#SBATCH --qos=interactive
#SBATCH --nodes=1
#SBATCH --time=00:04:00
#SBATCH --job-name=job-@BENCHMARK@
#SBATCH --output=job-@BENCHMARK@.o%j
#SBATCH --error=job-@BENCHMARK@.e%j

# set some openmp variables: 
# OMP_PLACES=threads maps OpenMP threads to hardware threads
# OMP_PROC_BIND=spread binds threads as evenly as possible
#
# see https://docs.nersc.gov/jobs/affinity/ for more information

# turn off OMP_NUM_THREADS as it doesn't play nicely with likwid-perfctr on Perlmutter
unset OMP_NUM_THREADS

export OMP_PLACES=threads
export OMP_PROC_BIND=spread

# use PERF_COUNTER_GROUP to tell likwif-perfctr which perf counter group to monitor
# the default here, FLOPS_DP, counts the number of double-precisions FLOPS
export PERF_COUNTER_GROUP=FLOPS_DP

# use the MARKER_FLAG variable to activate LIKWID's marker API, which will result in 
# perf counter data being collected only in the region of code surrounded by marker start/stop
# calls. If MARKER_FLAG is not defined, then the LIKWID marker API will not be activated,
# and the resulting performance data reflects the run of the entire program
export MARKER_FLAG="-m"

# iterate over some number of bodies and threads. 

# Note: only OpenMP codes have interaction with the OMP_NUM_THREADS env variable, 
# non-OpenMP jobs are not affected 

# make use of the OMP_SCHEDULE environment variable to set the thread scheduling 
# algorithm. 
# the default scheduling algorithm is static
# export OMP_SCHEDULE=static
# export OMP_SCHEDULE=dynamic

for N in 256 512 1024 2048
   do
   for t in 4 16 64
      do
         #export OMP_NUM_THREADS=$t
         
         #echo "OMP_NUM_THREADS = " $OMP_NUM_THREADS
         #./job-@BENCHMARK@
         #echo "Finished job-@BENCHMARK@ with $OMP_NUM_THREADS threads"

      echo likwid-perfctr $MARKER_FLAG -g $PERF_COUNTER_GROUP -C N:0-$maxcore ./@BENCHMARK@ $N 0 1 100 
      likwid-perfctr $MARKER_FLAG -g $PERF_COUNTER_GROUP -C N:0-$maxcore ./@BENCHMARK@ $N 0 1 100 

      done # iterate over concurrency level
#   srun -n 1  ./benchmark-@BENCHMARK@  # fall 2023, don't use srun to launch non-MPI jobs
# don't use --cpu-bind=threads on KNL when P % 272 != 0
# see https://docs.nersc.gov/jobs/affinity/#slurm-cpu-bind-flag
#   srun -n 1 --cpu-bind=threads ./benchmark-@BENCHMARK@
done